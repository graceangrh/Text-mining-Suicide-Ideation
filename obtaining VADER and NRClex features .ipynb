{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350a0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import ast\n",
    "from nrclex import NRCLex\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72510385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_data_new_negation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b27926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized_processed_text\"] = df[\"lemmatized_processed_text\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89c041c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negation(sentence):\t\n",
    "    '''\n",
    "    Input: Tokenized sentence (List of words)\n",
    "    Output: Tokenized sentence with negation handled (List of words)\n",
    "    '''\n",
    "    temp = int(0)\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                temp = 0\n",
    "                for l in syn.lemmas():\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                max_dissimilarity = 0\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2)\n",
    "                    if temp>max_dissimilarity:\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e6dac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Negation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aaf5c17108ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmatized_processed_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmatized_processed_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNegation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Negation' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"lemmatized_processed_text\"] = df[\"lemmatized_processed_text\"].apply(Negation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035270d6",
   "metadata": {},
   "source": [
    "# Get NRClex emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da46768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_lemmatized_processed_text'] = [' '.join(map(str, l)) for l in df['lemmatized_processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotions'] = df['clean_lemmatized_processed_text'].apply(lambda x: NRCLex(x).affect_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop(['emotions'], axis = 1), df['emotions'].apply(pd.Series)], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].apply(lambda x:1 if x == 'suicide' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15141370",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(df.clean_lemmatized_processed_text)\n",
    "tfidf_feat = pd.DataFrame(tfidf.toarray())\n",
    "#  Usin TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1982c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = tfidf_feat.join(df[[\"fear\", \"anger\", \"anticip\", \"trust\", \"surprise\", \"positive\", \"negative\", \"sadness\",\"disgust\", \"joy\", \"anticipation\", \"class\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15267e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_dataset.loc[:, final_dataset.columns != 'class']\n",
    ", final_dataset[\"class\"], test_size=0.25, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e9f0b",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM model\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989efc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, target_names=['Non-Suicide', 'Suicide']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Define labels for the confusion matrix\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Non-suicide', 'Suicide']\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=categories, yticklabels=categories, fmt='g')\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation: Accuracy Score\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(y_pred, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4a726",
   "metadata": {},
   "source": [
    "# Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee022526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the Logistic Regression classifier\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "logreg.fit(X_train,y_train)\n",
    "# predict the labels on validation dataset\n",
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_logreg, target_names=['Non-Suicide', 'Suicide']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(y_pred_logreg, y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "# Define labels for the confusion matrix\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Non-suicide', 'Suicide']\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Reds', xticklabels=categories, yticklabels=categories, fmt='g')\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76731fd",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "#predicted y\n",
    "y_pred_nb = naive_bayes_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_nb, target_names=['Non-Suicide', 'Suicide']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(y_pred_nb, y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "# Define labels for the confusion matrix\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Non-suicide', 'Suicide']\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', xticklabels=categories, yticklabels=categories, fmt='g')\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb60653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e94787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c3104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d08030e8",
   "metadata": {},
   "source": [
    "# Obtaining polarity scores from VADER lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842a2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import ast\n",
    "from nrclex import NRCLex\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import text2emotion as te\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a91f8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4810d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_data_new_negation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24aed769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized_processed_text\"] = df[\"lemmatized_processed_text\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94d274dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_lemmatized_processed_text'] = [' '.join(map(str, l)) for l in df['lemmatized_processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1c7e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232074/232074 [07:23<00:00, 523.55it/s]\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df[\"emotions\"] = df['clean_lemmatized_processed_text'].progress_apply(lambda x: analyzer.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db718270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop(['emotions'], axis = 1), df['emotions'].apply(pd.Series)], axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
